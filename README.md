# SmartWebCrawler

it is an easy Web Crawler With Java and Python

# Easy Web Crawler With Java

it is an easy Web Crawler with Java.

```
Language：Java
lib：Jsoup
version：v2.0
```

Key Point:

1.Jsoup 延迟访问页面的内容

2.然后使用Jsoup将请求的结果解析成Document对象

3.根据Document API像操作JS一样访问页面

博文介绍：[Java爬虫获取某个页面中指定节点的内容](https://blog.csdn.net/hadues/article/details/88983055)

# Python 网络爬虫解决方案

使用语言：Python

相关类库：urllib,beautifulsoup4

---

如果想爬取一个网址所有的a标签，那么你或许可以试试我写的这个基于beautifulsoup4的爬虫项目

博文介绍：[Python爬虫获取某个网页所有的a标签中的超链接网址](https://blog.csdn.net/hadues/article/details/88981686)

> 交流即分享，分享才能进步！不对之处，还请各位前辈多多指教。  by 星云

---

# 关于我

[星云CSDN博客](https://blog.csdn.net/hadues)

[星云博客园](http://www.cnblogs.com/xingyunblog)

[星云阿里云栖博客](https://yq.aliyun.com/u/xingyunsky)

[星云GitHub](https://github.com/geekxingyun)

[星云GitHub Page](http://www.520geek.cn)

[星云微博](https://weibo.com/xingyunsky)

# 免费加入我的知识星球

<p><a href="https://github.com/geekxingyun/SpringBootBestPracticesSample/blob/master/resources/images/my_world.png?raw=true"> <img src="https://github.com/geekxingyun/SpringBootBestPracticesSample/blob/master/resources/images/my_world.png?raw=true" width="253" height="340"><a><p>

# 联系我

> QQ：2864438285　
> 
> Email：fairy_xingyun@hotmail.com   

# 赞助支持

<h2>微信赞赏二维码</h2>
<p><img src="https://img2018.cnblogs.com/blog/622489/201812/622489-20181215164147325-217176189.png" alt="" width="303" height="282"></p>
<h2>支付宝赞赏二维码</h2>
<p><img src="https://img2018.cnblogs.com/blog/622489/201812/622489-20181215164420863-364321980.png" alt="" width="297" height="303"></p>

